{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task_1: Object Detection\n",
        "\n",
        "### **Using The Latest YOLO Version: YOLO_8**"
      ],
      "metadata": {
        "id": "DoBWdkk4eKNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAZRyzKiaJSE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YlRLI7pPLMQ",
        "outputId": "01e94ccd-6176-4a6a-8124-b4ac7c30577d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Access spesific path on my Drive\n",
        "%cd /content/drive/MyDrive/Intern_Task\n",
        "# !pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWy4Lqr2C2bN",
        "outputId": "f25c5323-be82-46c4-d075-ded0d17a4926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/18YpFLulPL1OQ3MnDFrGxgm4qO4tTQQ03/Yolo Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "OL38GBONaVC0",
        "outputId": "a28f9d63-1209-4128-ef1d-fad587c3c191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.120-py3-none-any.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.7/611.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: ultralytics\n",
            "Successfully installed ultralytics-8.0.120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6794b1-ec2e-4d52-f4f9-18f03196e3a5",
        "id": "ui8xgAMmHCrT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "5ff30c54-713c-4216-a718-70f0eae1ad69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_35s2Qe0HCrT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 448x640 5 persons, 12 cars, 1 traffic light, 205.7ms\n",
            "Speed: 27.7ms preprocess, 205.7ms inference, 69.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 5 persons, 12 cars, 1 traffic light, 1 backpack, 17.3ms\n",
            "Speed: 4.6ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 11 cars, 1 traffic light, 1 backpack, 15.6ms\n",
            "Speed: 4.3ms preprocess, 15.6ms inference, 9.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 12 cars, 1 traffic light, 15.8ms\n",
            "Speed: 9.6ms preprocess, 15.8ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 11 cars, 1 traffic light, 17.2ms\n",
            "Speed: 2.9ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 11 cars, 1 traffic light, 45.7ms\n",
            "Speed: 3.0ms preprocess, 45.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 12 cars, 20.8ms\n",
            "Speed: 2.8ms preprocess, 20.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 12 cars, 24.1ms\n",
            "Speed: 2.9ms preprocess, 24.1ms inference, 16.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 1 traffic light, 23.0ms\n",
            "Speed: 3.0ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 11 cars, 1 traffic light, 24.9ms\n",
            "Speed: 3.4ms preprocess, 24.9ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 1 traffic light, 45.6ms\n",
            "Speed: 7.7ms preprocess, 45.6ms inference, 11.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 13 cars, 1 traffic light, 19.7ms\n",
            "Speed: 3.8ms preprocess, 19.7ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 16.9ms\n",
            "Speed: 4.6ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 35.3ms\n",
            "Speed: 3.0ms preprocess, 35.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 1 traffic light, 32.3ms\n",
            "Speed: 3.0ms preprocess, 32.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 20.1ms\n",
            "Speed: 3.0ms preprocess, 20.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 13 cars, 1 traffic light, 27.2ms\n",
            "Speed: 2.9ms preprocess, 27.2ms inference, 15.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 13 cars, 1 traffic light, 22.5ms\n",
            "Speed: 3.1ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 15 cars, 1 traffic light, 28.3ms\n",
            "Speed: 3.1ms preprocess, 28.3ms inference, 12.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 14 cars, 1 traffic light, 27.0ms\n",
            "Speed: 3.2ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 1 traffic light, 12.2ms\n",
            "Speed: 5.7ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 8.5ms\n",
            "Speed: 3.0ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 8.0ms\n",
            "Speed: 3.1ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 7.9ms\n",
            "Speed: 3.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 1 traffic light, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 14 cars, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 1 traffic light, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 1 traffic light, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 13 cars, 1 traffic light, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 12 cars, 1 traffic light, 8.6ms\n",
            "Speed: 5.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 12 cars, 1 traffic light, 8.4ms\n",
            "Speed: 4.6ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 11 cars, 1 traffic light, 9.6ms\n",
            "Speed: 3.8ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 11 cars, 1 traffic light, 8.1ms\n",
            "Speed: 2.8ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 10 cars, 1 traffic light, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 12 cars, 1 traffic light, 10.7ms\n",
            "Speed: 3.7ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 12 cars, 1 traffic light, 10.1ms\n",
            "Speed: 5.0ms preprocess, 10.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 11 cars, 1 traffic light, 11.4ms\n",
            "Speed: 3.9ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 1 traffic light, 12.4ms\n",
            "Speed: 3.0ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 12 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 13 cars, 1 traffic light, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 13 cars, 1 traffic light, 10.1ms\n",
            "Speed: 3.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 1 traffic light, 6.5ms\n",
            "Speed: 3.7ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 13 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 1 traffic light, 6.8ms\n",
            "Speed: 3.4ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 1 traffic light, 6.7ms\n",
            "Speed: 3.3ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 13 cars, 1 traffic light, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 13 cars, 1 traffic light, 6.5ms\n",
            "Speed: 2.8ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 15 cars, 1 traffic light, 7.2ms\n",
            "Speed: 4.2ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 7.2ms\n",
            "Speed: 2.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 16 cars, 1 traffic light, 6.4ms\n",
            "Speed: 3.6ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 16 cars, 1 traffic light, 6.5ms\n",
            "Speed: 3.8ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 15 cars, 1 traffic light, 6.6ms\n",
            "Speed: 3.9ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 8.1ms\n",
            "Speed: 3.0ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 14 cars, 1 traffic light, 6.4ms\n",
            "Speed: 3.8ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 13 cars, 1 traffic light, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 6.5ms\n",
            "Speed: 3.8ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 7.9ms\n",
            "Speed: 3.7ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 6.5ms\n",
            "Speed: 3.5ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 15 cars, 1 traffic light, 6.7ms\n",
            "Speed: 3.7ms preprocess, 6.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 6.6ms\n",
            "Speed: 3.8ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 6.4ms\n",
            "Speed: 3.8ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 17 cars, 1 traffic light, 6.5ms\n",
            "Speed: 2.8ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 18 cars, 1 traffic light, 6.9ms\n",
            "Speed: 3.7ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 18 cars, 1 traffic light, 6.5ms\n",
            "Speed: 2.6ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 18 cars, 1 traffic light, 6.3ms\n",
            "Speed: 1.9ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 16 cars, 1 traffic light, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 17 cars, 1 traffic light, 7.1ms\n",
            "Speed: 2.8ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 17 cars, 1 traffic light, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 16 cars, 1 truck, 1 traffic light, 7.8ms\n",
            "Speed: 3.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 18 cars, 1 traffic light, 6.6ms\n",
            "Speed: 3.7ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 18 cars, 1 traffic light, 7.0ms\n",
            "Speed: 2.7ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 18 cars, 1 traffic light, 6.5ms\n",
            "Speed: 3.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 17 cars, 1 traffic light, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 17 cars, 1 traffic light, 6.5ms\n",
            "Speed: 3.7ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 1 person, 17 cars, 1 traffic light, 6.3ms\n",
            "Speed: 2.6ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 17 cars, 1 traffic light, 6.7ms\n",
            "Speed: 3.6ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 17 cars, 11.3ms\n",
            "Speed: 3.9ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 17 cars, 6.6ms\n",
            "Speed: 2.9ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 17 cars, 7.8ms\n",
            "Speed: 2.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 17 cars, 1 truck, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 18 cars, 6.5ms\n",
            "Speed: 3.0ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 18 cars, 6.9ms\n",
            "Speed: 3.3ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 18 cars, 6.7ms\n",
            "Speed: 3.3ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 16 cars, 6.3ms\n",
            "Speed: 3.9ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 17 cars, 6.3ms\n",
            "Speed: 3.7ms preprocess, 6.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 20 cars, 1 traffic light, 6.6ms\n",
            "Speed: 4.2ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 19 cars, 1 traffic light, 6.4ms\n",
            "Speed: 3.9ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 18 cars, 1 traffic light, 6.4ms\n",
            "Speed: 2.1ms preprocess, 6.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 16 cars, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 17 cars, 6.6ms\n",
            "Speed: 4.0ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 15 cars, 7.4ms\n",
            "Speed: 4.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 15 cars, 6.5ms\n",
            "Speed: 3.8ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 7.2ms\n",
            "Speed: 3.4ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 16 cars, 6.3ms\n",
            "Speed: 3.6ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 6.8ms\n",
            "Speed: 2.8ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 16 cars, 7.2ms\n",
            "Speed: 2.8ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 7.3ms\n",
            "Speed: 2.3ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 6.2ms\n",
            "Speed: 3.4ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 14 cars, 7.4ms\n",
            "Speed: 2.4ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 14 cars, 1 traffic light, 7.6ms\n",
            "Speed: 2.3ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 15 cars, 1 traffic light, 6.3ms\n",
            "Speed: 2.8ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 14 cars, 6.7ms\n",
            "Speed: 2.5ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 16 cars, 1 traffic light, 6.7ms\n",
            "Speed: 4.3ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 15 cars, 1 traffic light, 7.6ms\n",
            "Speed: 5.6ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 14 cars, 1 traffic light, 6.8ms\n",
            "Speed: 2.6ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 5 persons, 14 cars, 1 traffic light, 6.6ms\n",
            "Speed: 2.8ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 5 persons, 13 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 13 cars, 1 traffic light, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 13 cars, 1 traffic light, 6.8ms\n",
            "Speed: 3.9ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 15 cars, 1 traffic light, 6.6ms\n",
            "Speed: 3.8ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 14 cars, 1 traffic light, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 14 cars, 6.4ms\n",
            "Speed: 3.6ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 14 cars, 6.6ms\n",
            "Speed: 2.3ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 5 persons, 14 cars, 6.8ms\n",
            "Speed: 3.5ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 15 cars, 6.5ms\n",
            "Speed: 4.6ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 13 cars, 9.4ms\n",
            "Speed: 4.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 12 cars, 7.3ms\n",
            "Speed: 3.5ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 12 cars, 1 traffic light, 6.9ms\n",
            "Speed: 3.9ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 12 cars, 1 traffic light, 6.5ms\n",
            "Speed: 2.7ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 12 cars, 1 traffic light, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 11 cars, 1 traffic light, 6.7ms\n",
            "Speed: 3.7ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 11 cars, 1 traffic light, 7.0ms\n",
            "Speed: 4.5ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 11 cars, 1 traffic light, 6.9ms\n",
            "Speed: 4.3ms preprocess, 6.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 12 cars, 7.5ms\n",
            "Speed: 3.5ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 12 cars, 7.1ms\n",
            "Speed: 3.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 11 cars, 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 13 cars, 6.7ms\n",
            "Speed: 3.5ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 12 cars, 6.5ms\n",
            "Speed: 3.8ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 2 persons, 11 cars, 7.7ms\n",
            "Speed: 2.8ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 12 cars, 6.7ms\n",
            "Speed: 2.9ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 12 cars, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 4 persons, 11 cars, 6.4ms\n",
            "Speed: 3.9ms preprocess, 6.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 11 cars, 6.5ms\n",
            "Speed: 3.8ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 10 cars, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 11 cars, 6.2ms\n",
            "Speed: 2.7ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 10 cars, 6.6ms\n",
            "Speed: 4.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 3 persons, 9 cars, 7.3ms\n",
            "Speed: 2.7ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 5 persons, 11 cars, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 448x640 5 persons, 11 cars, 6.3ms\n",
            "Speed: 4.5ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total detected 2483, Total time (GPU): 2556.641\n"
          ]
        }
      ],
      "source": [
        "input_path = '/content/drive/MyDrive/Intern_Task/Test_sample_video.mp4'\n",
        "output_path = '/content/drive/MyDrive/Intern_Task/YOLO8_Output_video.mp4'\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(input_path)\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "encoder = cv2.VideoWriter(output_path, fourcc, 25, (frame_width, frame_height))\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "time_taken = 0\n",
        "total_detected_objects = 0\n",
        "\n",
        "while 1 :\n",
        "    ret, frame = cap.read()\n",
        "    if not ret :\n",
        "      break\n",
        "\n",
        "    result = model.predict(frame, device = 0)[0]\n",
        "\n",
        "    im = cv2.cvtColor(result.plot(), cv2.COLOR_BGR2RGB)  # get the labeled image\n",
        "    encoder.write(im)\n",
        "\n",
        "    time_taken +=  sum(result.speed.values())\n",
        "    total_detected_objects += len(result.boxes.data)\n",
        "\n",
        "\n",
        "cap.release()\n",
        "encoder.release()\n",
        "print(f'Total detected {total_detected_objects}, Total time (GPU): {time_taken :.3f}')"
      ]
    }
  ]
}